{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwonlim/Desktop/NLPQuestionClassifier/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import os\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "with open('./YoutubeComments/yt-comments.txt', 'r', encoding='utf-8') as file:\n",
    "      lines = file.readlines()\n",
    "      lines = [line.strip() for line in lines if line.strip()]\n",
    "      df = pd.DataFrame(lines, columns=['text'])\n",
    "      \n",
    "# For testing purpose:\n",
    "sentence1 = '''Thank you so much man, this is awesome content''' # False\n",
    "sentence2 = '''Can you make another video like this.''' # True\n",
    "sentence3 = '''Can I ask you this, make another video like this!''' # True\n",
    "sentence4 = '''What a beautiful video.''' # False\n",
    "sentence5 = '''What were you saying at 5:13 mark''' # True \n",
    "sentence6 = '''Where can I find more material like this''' # True\n",
    "sentence7 = '''I don't get when you said this''' # True\n",
    "sentence8 = '''What were you saying at 5:13 mark''' # True \n",
    "sentence9 = '''I don't understand this part that says''' # True\n",
    "sentence10 = '''I really don't get why people are saying bad things about this video''' # True\n",
    "\n",
    "\n",
    "def is_clean_english(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    allowed_chars = set(string.ascii_letters + string.digits + ' .,!?\\'\\\"')\n",
    "    return all(ord(char) < 128 and char in allowed_chars for char in text)\n",
    "\n",
    "def filter_dataframe(df, columns_to_check=None):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    if columns_to_check is None:\n",
    "        columns_to_check = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    stats = {\n",
    "        'total_rows': len(df),\n",
    "        'rows_removed': 0,\n",
    "        'removed_examples': [],\n",
    "        'issues_found': {col: 0 for col in columns_to_check}\n",
    "    }\n",
    "    \n",
    "    keep_mask = pd.Series(True, index=df.index)\n",
    "    \n",
    "    for col in columns_to_check:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        # Update mask to keep only clean English text\n",
    "        col_mask = df[col].apply(is_clean_english)\n",
    "        keep_mask &= col_mask\n",
    "        \n",
    "        # Update statistics\n",
    "        stats['issues_found'][col] = (~col_mask).sum()\n",
    "        \n",
    "        # Collect some examples of removed text\n",
    "        if len(stats['removed_examples']) < 5:\n",
    "            examples = df[~col_mask][col].head()\n",
    "            stats['removed_examples'].extend(\n",
    "                f\"Column '{col}': {text}\" for text in examples\n",
    "            )\n",
    "    \n",
    "    # Apply the filter\n",
    "    df_filtered = df_copy[keep_mask]\n",
    "    \n",
    "    # Update final statistics\n",
    "    stats['rows_removed'] = len(df) - len(df_filtered)\n",
    "    stats['rows_remaining'] = len(df_filtered)\n",
    "    stats['removal_percentage'] = (stats['rows_removed'] / stats['total_rows'] * 100)\n",
    "    \n",
    "    return df_filtered, stats\n",
    "\n",
    "#Do not try to explain or include information other than true or false in your response under any circumstance, just simply provide true or false answer.\n",
    "def is_question_by_llm(sentence):\n",
    "    llm = ChatOllama(model=\"llama3.1:latest\", temperature=0)\n",
    "    prompt = PromptTemplate.from_template(\n",
    "      \"\"\"\n",
    "      <s> [INST]\n",
    "      Return true if given sentence is a question or inquiry. Return false otherwise.\n",
    "      If a sentences contains '?', it's very likely to be a question, but a sentence is not a quesiton if contains '!'.\n",
    "      Consider sentences that include phrases like \"I don't understand...\" or \"I am confused...\" also as questions.\n",
    "      If unsure, return false.\n",
    "      [/INST] </s> \n",
    "      [INST]\n",
    "      Sentence: {sentence} \n",
    "      Answer: \n",
    "      [/INST]\n",
    "      \"\"\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # prompt = PromptTemplate.from_template(\n",
    "    #   \"\"\"\n",
    "    #   <s> [INST] \n",
    "    #   Return true if given sentence is a question or inquiry or a statement that induces response. This includes statement that expresses confusion or ambiguity. Return false otherwise.\n",
    "    #   Do not try to explain, just simply provide true or false answer.\n",
    "    #   [/INST] </s> \n",
    "    #   [INST]\n",
    "    #   Sentence: {sentence} \n",
    "    #   Answer: \n",
    "    #   [/INST]\n",
    "    #   \"\"\"\n",
    "    # )\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    query_chain = chain.invoke(\n",
    "        {\n",
    "            \"sentence\": sentence\n",
    "        }\n",
    "    )\n",
    "    return query_chain.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shuffle\n",
    "# shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# # filter out symbols, and grab first n = 100 data points\n",
    "# result_df, stats = filter_dataframe(shuffled_df.head(100))\n",
    "\n",
    "# # remove processed 100 data points from df\n",
    "# merged_df = shuffled_df.merge(result_df, on=['text'], how='left', indicator=True)\n",
    "# reduced_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "# df = reduced_df.copy()\n",
    "\n",
    "# # Apply the question detection function\n",
    "# result_df['label'] = result_df['text'].apply(is_question_by_llm)\n",
    "\n",
    "\n",
    "# # Clean the response into 1 or 0\n",
    "# result_df['label'] = result_df['label'].apply(lambda x: 1 if str(x).strip().lower().replace('.','') == 'true' else 0)\n",
    "# file_exists = os.path.isfile('output.csv')\n",
    "# result_df.to_csv('output.csv', \n",
    "#                  mode='a',  # append mode\n",
    "#                  header=not file_exists,  # only write header if file doesn't exist\n",
    "#                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df, stats = filter_dataframe(df.head(10))\n",
    "\n",
    "# Apply the question detection function\n",
    "result_df['label'] = result_df['text'].apply(is_question_by_llm)\n",
    "\n",
    "# Clean the response into 1 or 0\n",
    "result_df['label'] = result_df['label'].apply(lambda x: 1 if str(x).strip().lower().replace('.','') == 'true' else 0)\n",
    "file_exists = os.path.isfile('output.csv')\n",
    "result_df.to_csv('output.csv', \n",
    "                 mode='a',  # append mode\n",
    "                 header=not file_exists,  # only write header if file doesn't exist\n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the instructions, I would answer:\n",
      "\n",
      "**False**\n",
      "\n",
      "The sentence contains an exclamation mark '!', which suggests it's a statement rather than a question. The presence of '!'' is actually a strong indicator that it's not a question, according to the instructions.\n"
     ]
    }
   ],
   "source": [
    "print(is_question_by_llm(\"You did that at the end on purpose!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
